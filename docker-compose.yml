services:
  # Serviço do Django (web)
  django-api:
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "0.6G"
    user: ${DJANGO_API_UID}:${DATA_GID}
    build:
      context: backend
      dockerfile: Dockerfile
      args:
        - USER=${DJANGO_API_USER}
        - UID=${DJANGO_API_UID}
        - GID=${DATA_GID}
    restart: unless-stopped
    environment:
      - ENTRYPOINT_PATH=/src/scripts/docker-django-api-entrypoint.sh
    volumes:
      - ${DATA_ROOT_DIR}:${DATA_ROOT_DIR}:rw
      - backend/django-api-logs:/logs
    ports:
      - "8000:8000"
    env_file:
      - backend/.env
    networks:
      - bridge-network
    depends_on:
      - db
      - rabbitmq
      - redis

  django-worker:
    build:
      context: backend
      dockerfile: Dockerfile
      args:
        - USER=${DJANGO_WORKER_USER}
        - UID=${DJANGO_WORKER_UID}
        - GID=${DATA_GID}
    restart: unless-stopped
    user: ${DJANGO_WORKER_UID}:${DATA_GID}
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: "4G"
    volumes:
      - ${DATA_ROOT_DIR}:${DATA_ROOT_DIR}:rw
    env_file:
      - backend/.env
    environment:
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - ENTRYPOINT_PATH=/src/scripts/docker-django-worker-entrypoint.sh
    networks:
      - bridge-network
    depends_on:
      - rabbitmq
    logging:
      driver: "json-file" # Default logging driver
      options:
        max-size: "10m" # Rotate logs after they reach 10 MB
        max-file: "3" # Keep a maximum of 3 log files

  # Serviço Celery Worker para PDF (com acesso ao Django e ao pdf_processor)
  pdf2chemicals-worker:
    build:
      context: backend
      dockerfile: Dockerfile
      args:
        - USER=${PDF2CHEMICALS_WORKER_USER}
        - UID=${PDF2CHEMICALS_WORKER_UID}
        - GID=${DATA_GID}
    restart: unless-stopped
    hostname: ${PDF2CHEMICALS_WORKER_HOSTNAME}
    deploy:
      resources:
        limits:
          cpus: "2"
          memory: "4G"
    networks:
      bridge-network:
        ipv4_address: ${PDF2CHEMICALS_WORKER_HOSTNAME_IPV4}
    extra_hosts:
      - ${TORQUE_SERVER}:${TORQUE_SERVER_HOST}
    volumes:
      - ${DATA_ROOT_DIR}:${DATA_ROOT_DIR}:rw
      - ${HOST_USER_LIST}:${HOST_USER_LIST}:ro
      - ${HOST_USER_PASSWORD_LIST}:${HOST_USER_PASSWORD_LIST}:ro
      - ${HOST_GROUP_LIST}:${HOST_GROUP_LIST}:ro
      - ${TORQUE_HOME}:${TORQUE_HOME}:ro
      - ${TORQUE_USER_HOME}:${TORQUE_USER_HOME}
      - ${TORQUE_ROOT_DIR}/server_name:${TORQUE_ROOT_DIR}/server_name:ro
      - ${TORQUE_ROOT_DIR}/server_priv/accounting:${TORQUE_ROOT_DIR}/server_priv/accounting:ro
      - ${TORQUE_ROOT_DIR}/server_logs:${TORQUE_ROOT_DIR}/server_logs:ro
      - ${TORQUE_ROOT_DIR}/mom_logs:${TORQUE_ROOT_DIR}/mom_logs:ro
    env_file:
      - backend/.env
    environment:
      - ENTRYPOINT_PATH=/src/scripts/docker-pdf2chemicals-worker-entrypoint.sh
      - TORQUE_HOME=${TORQUE_HOME}
      - TORQUE_SERVER=${TORQUE_SERVER}
      - CELERY_BROKER_URL=${CELERY_BROKER_URL}
      - PATH=${TORQUE_HOME}/bin:${TORQUE_HOME}/sbin:$PATH
      - LD_LIBRARY_PATH=${TORQUE_HOME}/lib:$LD_LIBRARY_PATH
    depends_on:
      - rabbitmq
    logging:
      driver: "json-file" # Default logging driver
      options:
        max-size: "10m" # Rotate logs after they reach 10 MB
        max-file: "3" # Keep a maximum of 3 log files

  db:
    build:
      context: backend/db
      dockerfile: Dockerfile
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "2G"
    networks:
      - bridge-network
    environment:
      POSTGRES_PASSWORD: ${DATABASE_PASSWORD}
      POSTGRES_USER: ${DATABASE_USER}
      POSTGRES_DB: ${DATABASE_NAME}
    env_file:
      - backend/.env
    command: >
      postgres -c port=5477
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5477:5477"
    restart: unless-stopped

  redis:
    image: redis:7.2.4-alpine
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "2G"
    networks:
      - bridge-network
    command: >
      redis-server --appendonly yes --requirepass "$REDIS_PASSWORD"
    volumes:
      - redis-data:/data
    ports:
      - "6379:6379"
    env_file:
      - backend/.env
    environment:
      REDIS_PASSWORD: "${REDIS_PASSWORD}"
    restart: unless-stopped

  # Serviço RabbitMQ (broker de mensagens)
  rabbitmq:
    image: rabbitmq:4-management-alpine
    deploy:
      resources:
        limits:
          cpus: "1"
          memory: "1G"
    networks:
      - bridge-network
    environment:
      RABBITMQ_SERVER_ADDITIONAL_ERL_ARGS: "-rabbit consumer_timeout 31622400000"
    ports:
      - "5672:5672" # Porta padrão do RabbitMQ
      - "15672:15672" # Porta para a interface de administração do RabbitMQ
    restart: unless-stopped

  clam-container:
    container_name: clam-container-01
    image: clamav/clamav:stable_base
    deploy:
      resources:
        limits:
          cpus: "0.5"
          memory: "3G"
    networks:
      - bridge-network
    ports:
      - "3310:3310"
      - "7357:7357"
    volumes:
      - clamav-data:/var/lib/clamav
      - clamav-logs:/var/log/clamav
    restart: unless-stopped

networks:
  bridge-network:
    driver: bridge
    ipam:
      config:
        - subnet: ${LABSOA_WEBSITE_SUBNET}
    env_file:
      - backend/.env

volumes:
  redis-data:
  media:
  clamav-data:
  clamav-logs:
  django-api-logs:
  postgres_data:
